{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"VP7q3dxZJd5b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700473559702,"user_tz":-330,"elapsed":29648,"user":{"displayName":"YASH","userId":"06056076789739563508"}},"outputId":"3132cf90-01fc-45ce-db81-b0d855e80051"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Tfn3SDFHJfpP","executionInfo":{"status":"ok","timestamp":1700473566359,"user_tz":-330,"elapsed":6665,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"outputs":[],"source":["import random\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import PIL\n","from PIL import Image\n","import tensorflow  as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Reshape, UpSampling2D, Conv2D, BatchNormalization\n","from tensorflow.keras.layers import LeakyReLU, Dropout, ZeroPadding2D, Flatten, Activation\n","from tensorflow.keras.optimizers import Adam\n","import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","#Settings\n","sns.set(rc={\"axes.facecolor\":\"#EDE9DE\",\"figure.facecolor\":\"#D8CA7E\"})"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"WI0mlxvaJqw3","colab":{"base_uri":"https://localhost:8080/","height":401},"executionInfo":{"status":"error","timestamp":1700473566359,"user_tz":-330,"elapsed":14,"user":{"displayName":"YASH","userId":"06056076789739563508"}},"outputId":"3f0e11a2-5448-4e93-e30e-545c7d01397a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 0 files belonging to 1 classes.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-94f1d87fcb65>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Import as tf.Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dataset_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m         )\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0;34mf\"No images found in directory {directory}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;34mf\"Allowed formats: {ALLOWLIST_FORMATS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No images found in directory /content/drive/MyDrive/Arc-welding residual stress images/Images. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"]}],"source":["data_path = \"/content/drive/MyDrive/Arc-welding residual stress images/Images\"\n","batch_s = 64\n","#Import as tf.Dataset\n","data = tf.keras.preprocessing.image_dataset_from_directory(data_path, label_mode = None, image_size = (64,64), batch_size = batch_s)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xcVOJnuKEvp","executionInfo":{"status":"aborted","timestamp":1700473566360,"user_tz":-330,"elapsed":9,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"outputs":[],"source":["latent_dim = 100\n","g_resolution=2\n","\n","#Building a Generator\n","generator = Sequential()\n","generator.add(Dense(4*4*256,activation=\"relu\",input_dim=latent_dim))\n","generator.add(Reshape((4,4,256)))\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n","generator.add(BatchNormalization(momentum=0.8))\n","generator.add(Activation(\"relu\"))\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n","generator.add(BatchNormalization(momentum=0.8))\n","generator.add(Activation(\"relu\"))\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(256,kernel_size=3,padding=\"same\"))#\n","generator.add(BatchNormalization(momentum=0.8))\n","generator.add(Activation(\"relu\"))\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n","generator.add(BatchNormalization(momentum=0.8))\n","generator.add(Activation(\"relu\"))\n","generator.add(Conv2D(3,kernel_size=3,padding=\"same\"))\n","generator.add(Activation(\"tanh\"))\n","\n","generator.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBeaBkV4KLPz","executionInfo":{"status":"aborted","timestamp":1700473566360,"user_tz":-330,"elapsed":9,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"outputs":[],"source":["#Creating a random seed and output from generator\n","seed = tf.random.normal([1, latent_dim])\n","Generated_Portrait = generator(seed, training=False)\n","#Plotting the image output of generator without training\n","plt.imshow(Generated_Portrait[0, :, :, 0])\n","plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWqf8gX9KRxL","executionInfo":{"status":"aborted","timestamp":1700473566360,"user_tz":-330,"elapsed":9,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"outputs":[],"source":["#Building a Discriminator\n","discriminator = Sequential()\n","discriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(64,64,3), padding=\"same\"))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","discriminator.add(Dropout(0.25))\n","discriminator.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n","discriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\n","discriminator.add(BatchNormalization(momentum=0.8))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","discriminator.add(Dropout(0.25))\n","discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n","discriminator.add(BatchNormalization(momentum=0.8))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","discriminator.add(Dropout(0.25))\n","discriminator.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n","discriminator.add(BatchNormalization(momentum=0.8))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","discriminator.add(Dropout(0.25))\n","discriminator.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n","discriminator.add(BatchNormalization(momentum=0.8))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","discriminator.add(Dropout(0.25))\n","discriminator.add(Flatten())\n","discriminator.add(Dense(1, activation=\"sigmoid\"))\n","\n","discriminator.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0wI0DAmKdrd","executionInfo":{"status":"aborted","timestamp":1700473566360,"user_tz":-330,"elapsed":9,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"outputs":[],"source":["#for the random image generated\n","Discriminator_Verdict = discriminator(Generated_Portrait)\n","print (Discriminator_Verdict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQNrqYhIKkCp","executionInfo":{"status":"aborted","timestamp":1700473566360,"user_tz":-330,"elapsed":8,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"outputs":[],"source":["class GAN(tf.keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super(GAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(GAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n","        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [self.d_loss_metric, self.g_loss_metric]\n","\n","    def train_step(self, real_images):\n","        # Sample random points in the latent space\n","        batch_size = tf.shape(real_images)[0]\n","        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        # Decode them to fake images\n","        generated_images = self.generator(seed)\n","        # Combine them with real images\n","        combined_images = tf.concat([generated_images, real_images], axis=0)\n","        # Assemble labels discriminating real from fake images\n","        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n","        # Add random noise to the labels - important trick!\n","        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n","        # Train the discriminator\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_images)\n","            d_loss = self.loss_fn(labels, predictions)\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n","\n","        # Sample random points in the latent space\n","        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n","\n","        # Assemble labels that say \"all real images\"\n","        misleading_labels = tf.zeros((batch_size, 1))\n","\n","        # Train the generator (note that we should *not* update the weights of the discriminator)!\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(self.generator(seed))\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","\n","        # Update metrics\n","        self.d_loss_metric.update_state(d_loss)\n","        self.g_loss_metric.update_state(g_loss)\n","        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LblRgLrKsdZ","executionInfo":{"status":"aborted","timestamp":1700473566361,"user_tz":-330,"elapsed":9,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"outputs":[],"source":["#Defining the number of epochs\n","epochs = 200\n","#The optimizers for Generator and Discriminator\n","discriminator_opt = tf.keras.optimizers.Adamax(1.5e-4,0.5)\n","generator_opt = tf.keras.optimizers.Adamax(1.5e-4,0.5)\n","#To compute cross entropy loss\n","loss_fn = tf.keras.losses.BinaryCrossentropy()\n","\n","#Defining GAN Model\n","model = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n","\n","#Compiling GAN Model\n","model.compile(d_optimizer=discriminator_opt, g_optimizer=generator_opt, loss_fn=loss_fn)\n","\n","#Fitting the GAN\n","history = model.fit(data, epochs=epochs)\n"]},{"cell_type":"code","source":["#Number of images to be generate\n","num_img=18\n","\n","#A function to generate and save images\n","def Image_Generator():\n","    Generated_Paintings = []\n","    seed = tf.random.normal([num_img, latent_dim])\n","    generated_image = generator(seed)\n","    generated_image *= 255\n","    generated_image = generated_image.numpy()\n","    for i in range(num_img):\n","            img = tf.keras.preprocessing.image.array_to_img(generated_image[i])\n","            Generated_Paintings.append(img)\n","            img.save(\"Potraits{:02d}.png\".format(i))\n","    return\n","\n","#Generating images\n","Images = Image_Generator()"],"metadata":{"id":"Tu2nwoKLi4X0","executionInfo":{"status":"aborted","timestamp":1700473566361,"user_tz":-330,"elapsed":9,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b_sOorVUi6Gg","executionInfo":{"status":"aborted","timestamp":1700473566361,"user_tz":-330,"elapsed":9,"user":{"displayName":"YASH","userId":"06056076789739563508"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}